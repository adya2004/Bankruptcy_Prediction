{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase-3 : Classification Model** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final phase where we integrate embeddings obtained from Knowledge Graph, Financial ratios, and Volatility index data to one dataframe, which is trained on logistic regression resulting in different evaluation results, for different combination of the model\n",
    "\n",
    "This file also shows how we can combine **structerd data** like table of financial ratios, along with **unstructered data** like textual data (summary and KG in this case) to get final result of logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bankrupt_file_path = r'Dataset\\FinancialRatios\\bankrupt_financial_ratio_dataset_final.xlsx'\n",
    "healthy_file_path = r'Dataset\\FinancialRatios\\healthy_financial_ratio_dataset _final.xlsx'\n",
    "\n",
    "bankrupt_data = pd.read_excel(bankrupt_file_path)\n",
    "healthy_data = pd.read_excel(healthy_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mannualy mapped the namings because of complexity of retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually match the names\n",
    "matches = {\n",
    "    \"ABGSHIP\": \"ABG Shipyard Limited\",\n",
    "    \"ADHUNIK\": \"Adhunik Metaliks Limited\",\n",
    "    \"ANGIND\": \"ANG Industries Limited\",\n",
    "    \"ASHAPURMIN\": \"Ashapura Minechem Limited\",\n",
    "    \"BAFNAPH\": \"Bafna Pharmaceuticals Limited\",\n",
    "    \"BHUSANSTL\": \"Bhushan Steel Limited\",\n",
    "    \"CANDC\": \"C & C Constructions Limited\",\n",
    "    \"EASUNREYRL\": \"Easun Reyrolle Limited\",\n",
    "    \"EDL\": \"Empee Distilleries Limited\",\n",
    "    \"GALLANT\": \"Gallantt Ispat Ltd\",\n",
    "    \"GEMINI\": \"Gemini Communication Limited\",\n",
    "    \"GUJNRECOKE\": \"Gujarat NRE Coke Limited\",\n",
    "    \"INDOSOLAR\": \"Indosolar Limited\",\n",
    "    \"IVRCLINFRA\": \"IVRCL Limited\",\n",
    "    \"JAIHINDPRO\": \"Jaihind Projects Limited\",\n",
    "    \"JENSONICOL\": \"Jenson & Nicholson (India) Limited\",\n",
    "    \"JPINFRATEC\": \"Jaypee Infratech Limited\",\n",
    "    \"KWALITY\": \"kwality limited\",\n",
    "    \"ADVENZYM\": \"Advanced Enzyme Tech Ltd.\",\n",
    "    \"AFFLE\": \"Affle (India) Ltd.\",\n",
    "    \"ALEMBICLTD\": \"Alembic Pharmaceuticals Ltd.\",\n",
    "    \"AMARAJABAT\": \"Amara Raja Batteries Ltd.\",\n",
    "    \"ASTERDM\": \"Aster DM Healthcare Ltd.\",\n",
    "    \"AVANTIFEED\": \"Avanti Feeds Ltd.\",\n",
    "    \"BALRAMCHIN\": \"Balrampur Chini Mills Ltd.\",\n",
    "    \"CEATLTD\": \"Ceat Ltd.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Financial ratio dataset consider only features and files which are accounting for change in classification model accuray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vijay\\AppData\\Local\\Temp\\ipykernel_3368\\337448102.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bankrupt_df = pd.concat([bankrupt_df, row], ignore_index=True)\n",
      "C:\\Users\\vijay\\AppData\\Local\\Temp\\ipykernel_3368\\337448102.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  healthy_df = pd.concat([healthy_df, row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "bankrupt_output_path = r'output\\bankrupt'\n",
    "healthy_output_path = r'output\\healthy'\n",
    "import os\n",
    "import json\n",
    "\n",
    "bankrupt_df = pd.DataFrame(columns=bankrupt_data.columns)\n",
    "healthy_df = pd.DataFrame(columns=healthy_data.columns)\n",
    "\n",
    "for file in os.listdir(bankrupt_output_path):\n",
    "    # print(file)\n",
    "    row = bankrupt_data.loc[(bankrupt_data['Folder_name'] == matches[file.split('_')[0]]) & (bankrupt_data['Feature_name'] == int(file.split('_')[-2]))]\n",
    "    bankrupt_df = pd.concat([bankrupt_df, row], ignore_index=True)\n",
    "\n",
    "for file in os.listdir(healthy_output_path):\n",
    "    # print(file)\n",
    "    row = healthy_data.loc[(healthy_data['Folder_name'] == matches[file.split('_')[0]]) & (healthy_data['Feature_name'] == int(file.split('_')[-2]))]\n",
    "    healthy_df = pd.concat([healthy_df, row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "bankrupt_df[\"Label\"] = 1\n",
    "healthy_df[\"Label\"] = 0\n",
    "\n",
    "financial_df = pd.concat([bankrupt_df, healthy_df], ignore_index=True)\n",
    "\n",
    "missing_values = financial_df.isnull().sum()\n",
    "# print(missing_values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine **Knowledge Graph Embeddings** with **Financial Ratios** with **Special Features** in consideration for building up the dataset, which is sent as an input for the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "_embeddings = pd.read_csv(r\"output\\embeddings.csv\")\n",
    "merged_df = pd.concat([financial_df, _embeddings], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "vix_path = r'Dataset\\FinancialRatios\\VIX_yearly_means.csv'\n",
    "vix_df = pd.read_csv(vix_path)\n",
    "overall_mean_vix = vix_df['Close '].mean()\n",
    "merged_df = merged_df.merge(vix_df, left_on='Feature_name', right_on='Year', how='left')\n",
    "merged_df['Close '] = merged_df['Close '].fillna(overall_mean_vix)\n",
    "merged_df.drop(columns=['Year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "selected_ratios = [\"x1\", \"x4\", \"x13\", \"x15\", \"x26\", \"x28\", \"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\", \"k8\", \"k9\", \"k10\"]\n",
    "\n",
    "merged_df = merged_df.sort_values(by=['Folder_name', 'Feature_name'])\n",
    "\n",
    "X = merged_df[selected_ratios]\n",
    "y = merged_df[\"Label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here We included **KG Embeddings**, **VIX data** and **Financial ratios** as input for logistic regression model,\n",
    "\n",
    "This is done in the sense of comparing it with other structure data outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ratios_vix = [\"x1\", \"x4\", \"x13\", \"x15\", \"x26\", \"x28\", 'k1', 'k2', 'k3', 'k4', 'k5', 'k6', 'k7', 'k8', 'k9', 'k10',\n",
    "       'Open ', 'High ', 'Low ', 'Close ', 'Prev. Close ', 'Change ',\n",
    "       '% Change ']\n",
    "\n",
    "merged_df = merged_df.sort_values(by=['Folder_name', 'Feature_name'])\n",
    "\n",
    "X_vix = merged_df[selected_ratios_vix]\n",
    "y_vix = merged_df[\"Label\"]\n",
    "\n",
    "X_train_vix, X_test_vix, y_train_vix, y_test_vix = train_test_split(X_vix, y_vix, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is for financial ratios only\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# selected_ratios = [\"x1\", \"x4\", \"x13\", \"x15\", \"x26\", \"x28\"]\n",
    "\n",
    "# financial_df = financial_df.sort_values(by=['Folder_name', 'Feature_name'])\n",
    "\n",
    "# X = financial_df[selected_ratios]\n",
    "# y = financial_df[\"Label\"]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression ....\n",
      "----------------------------------------------\n",
      "\n",
      "Logistic Regression Performance:\n",
      "accuracy: 0.9500\n",
      "precision: 1.0000\n",
      "recall: 0.9091\n",
      "f1: 0.9524\n",
      "roc_auc: 1.0000\n",
      "cv_accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000)\n",
    "}\n",
    "\n",
    "model_performance = {}\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name} ....\")\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', imputer),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "    cv_accuracy = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
    "\n",
    "    model_performance[model_name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"cv_accuracy\": cv_accuracy\n",
    "    }\n",
    "print(\"----------------------------------------------\")\n",
    "for model_name, metrics in model_performance.items():\n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression ....\n",
      "\n",
      "Logistic Regression Performance:\n",
      "accuracy: 0.9000\n",
      "precision: 1.0000\n",
      "recall: 0.8182\n",
      "f1: 0.9000\n",
      "roc_auc: 1.0000\n",
      "cv_accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000)\n",
    "}\n",
    "\n",
    "model_performance = {}\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name} ....\")\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', imputer),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "    cv_accuracy = cross_val_score(pipeline, X_train_vix, y_train_vix, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "    pipeline.fit(X_train_vix, y_train_vix)\n",
    "    y_pred = pipeline.predict(X_test_vix)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test_vix)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    accuracy = accuracy_score(y_test_vix, y_pred)\n",
    "    precision = precision_score(y_test_vix, y_pred)\n",
    "    recall = recall_score(y_test_vix, y_pred)\n",
    "    f1 = f1_score(y_test_vix, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test_vix, y_pred_proba) if y_pred_proba is not None else None\n",
    "\n",
    "    model_performance[model_name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"cv_accuracy\": cv_accuracy\n",
    "    }\n",
    "\n",
    "for model_name, metrics in model_performance.items():\n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
