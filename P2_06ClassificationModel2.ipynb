{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase-3 : Classification Model** \n",
    "\n",
    "This is the final phase where we integrate embeddings obtained from Knowledge Graph, Financial ratios, and Volatility index data to one dataframe, which is trained on logistic regression resulting in different evaluation results, for different combination of the model\n",
    "\n",
    "This file also shows how we can combine **structerd data** like table of financial ratios, along with **unstructered data** like textual data (summary and KG in this case) to get final result of logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually match the names\n",
    "matches = {\n",
    "    \"ABGSHIP\": \"ABG Shipyard Limited\",\n",
    "    \"ADHUNIK\": \"Adhunik Metaliks Limited\",\n",
    "    \"ANGIND\": \"ANG Industries Limited\",\n",
    "    \"ASHAPURMIN\": \"Ashapura Minechem Limited\",\n",
    "    \"BAFNAPH\": \"Bafna Pharmaceuticals Limited\",\n",
    "    \"BHUSANSTL\": \"Bhushan Steel Limited\",\n",
    "    \"CANDC\": \"C & C Constructions Limited\",\n",
    "    \"EASUNREYRL\": \"Easun Reyrolle Limited\",\n",
    "    \"EDL\": \"Empee Distilleries Limited\",\n",
    "    \"GALLANT\": \"Gallantt Ispat Ltd\",\n",
    "    \"GEMINI\": \"Gemini Communication Limited\",\n",
    "    \"GUJNRECOKE\": \"Gujarat NRE Coke Limited\",\n",
    "    \"INDOSOLAR\": \"Indosolar Limited\",\n",
    "    \"IVRCLINFRA\": \"IVRCL Limited\",\n",
    "    \"JAIHINDPRO\": \"Jaihind Projects Limited\",\n",
    "    \"JENSONICOL\": \"Jenson & Nicholson (India) Limited\",\n",
    "    \"JPINFRATEC\": \"Jaypee Infratech Limited\",\n",
    "    \"KWALITY\": \"kwality limited\",\n",
    "    \"ADVENZYM\": \"Advanced Enzyme Tech Ltd.\",\n",
    "    \"AFFLE\": \"Affle (India) Ltd.\",\n",
    "    \"ALEMBICLTD\": \"Alembic Pharmaceuticals Ltd.\",\n",
    "    \"AMARAJABAT\": \"Amara Raja Batteries Ltd.\",\n",
    "    \"ASTERDM\": \"Aster DM Healthcare Ltd.\",\n",
    "    \"AVANTIFEED\": \"Avanti Feeds Ltd.\",\n",
    "    \"BALRAMCHIN\": \"Balrampur Chini Mills Ltd.\",\n",
    "    \"CEATLTD\": \"Ceat Ltd.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankrupt_data = pd.read_excel(r'classifiaction model\\bankrupt_financial_ratio_dataset_final.xlsx')\n",
    "healthy_data = pd.read_excel(r'classifiaction model\\healthy_financial_ratio_dataset _final.xlsx')\n",
    "vix_data = pd.read_csv(r'classifiaction model\\VIX_yearly_means.csv')\n",
    "\n",
    "bankrupt_data['Bankruptcy'] = 1\n",
    "healthy_data['Bankruptcy'] = 0\n",
    "\n",
    "data = pd.concat([bankrupt_data, healthy_data], ignore_index=True)\n",
    "\n",
    "data.rename(columns={'Feature_name': 'Year'}, inplace=True)\n",
    "data = data.merge(vix_data, on='Year', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankrupt_output_path = r'output\\bankrupt'\n",
    "healthy_output_path = r'output\\healthy'\n",
    "import os\n",
    "\n",
    "bankrupt_df = pd.DataFrame(columns=bankrupt_data.columns)\n",
    "healthy_df = pd.DataFrame(columns=healthy_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vijay\\AppData\\Local\\Temp\\ipykernel_16076\\820206306.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bankrupt_df = pd.concat([bankrupt_df, row], ignore_index=True)\n",
      "C:\\Users\\vijay\\AppData\\Local\\Temp\\ipykernel_16076\\820206306.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  healthy_df = pd.concat([healthy_df, row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(bankrupt_output_path):\n",
    "    # print(file)\n",
    "    row = bankrupt_data.loc[(bankrupt_data['Folder_name'] == matches[file.split('_')[0]]) & (bankrupt_data['Feature_name'] == int(file.split('_')[-2]))]\n",
    "    bankrupt_df = pd.concat([bankrupt_df, row], ignore_index=True)\n",
    "\n",
    "for file in os.listdir(healthy_output_path):\n",
    "    # print(file)\n",
    "    row = healthy_data.loc[(healthy_data['Folder_name'] == matches[file.split('_')[0]]) & (healthy_data['Feature_name'] == int(file.split('_')[-2]))]\n",
    "    healthy_df = pd.concat([healthy_df, row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankrupt_df[\"Label\"] = 1\n",
    "healthy_df[\"Label\"] = 0\n",
    "import os\n",
    "os.makedirs('output/classification_models', exist_ok=True)\n",
    "\n",
    "financial_df = pd.concat([bankrupt_df, healthy_df], ignore_index=True)\n",
    "\n",
    "overall_mean_vix = vix_data['Close '].mean()\n",
    "\n",
    "drop_columns = ['Bankruptcy', 'path', 'Folder_name', 'Feature_name', 'Label']\n",
    "\n",
    "def print_metrics(model_name, y_test, y_preds, y_probs):\n",
    "    print(f\"{model_name} Performance:\")\n",
    "    print(f\"Test Accuracy: {accuracy_score(y_test, y_preds):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_preds):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_preds):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_preds):.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_probs):.4f}\\n\")\n",
    "\n",
    "def merge_and_train(embedding_loc, model_name):\n",
    "    _embeddings = pd.read_csv(embedding_loc)\n",
    "    merged_df = pd.concat([financial_df, _embeddings], axis=1)\n",
    "\n",
    "    merged_df = merged_df.merge(vix_data, left_on='Feature_name', right_on='Year', how='left')\n",
    "    merged_df['Close '] = merged_df['Close '].fillna(overall_mean_vix)\n",
    "    merged_df.drop(columns=['Year'], inplace=True)\n",
    "\n",
    "    merged_df = merged_df.sort_values(by=['Folder_name', 'Feature_name'])\n",
    "    merged_df.dropna(inplace=True)\n",
    "    X = merged_df.drop(columns=drop_columns)\n",
    "    y = merged_df['Label']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # Step 5: Logistic Regression\n",
    "    log_model = LogisticRegression()\n",
    "    log_model.fit(X_train, y_train)\n",
    "    log_preds = log_model.predict(X_test)\n",
    "    log_probs = log_model.predict_proba(X_test)[:, 1]\n",
    "    print_metrics(\"Logistic Regression\", y_test, log_preds, log_probs)\n",
    "    with open('output/classification_models/lr_' + model_name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(log_model, f)\n",
    "    print(\"LogisticRegression model saved!\")\n",
    "    print()\n",
    "    \n",
    "    # Step 6: Random Forest\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_preds = rf_model.predict(X_test)\n",
    "    rf_probs = rf_model.predict_proba(X_test)[:, 1]\n",
    "    print_metrics(\"Random Forest\", y_test, rf_preds, rf_probs)\n",
    "    with open('output/classification_models/rf_' + model_name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(rf_model, f)\n",
    "    print(\"RandomForest model saved!\")\n",
    "    print()\n",
    "    # Step 7: XGBoost\n",
    "    xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    xgb_preds = xgb_model.predict(X_test)\n",
    "    xgb_probs = xgb_model.predict_proba(X_test)[:, 1]\n",
    "    print_metrics(\"XGBoost\", y_test, xgb_preds, xgb_probs)\n",
    "    with open('output/classification_models/xgb_' + model_name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(xgb_model, f)\n",
    "    print(\"XGBoost model saved!\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_final_dataset(embeddings_loc, file_name):\n",
    "    _embeddings = pd.read_csv(embeddings_loc)\n",
    "    merged_df = pd.concat([financial_df, _embeddings], axis=1)\n",
    "\n",
    "    merged_df = merged_df.merge(vix_data, left_on='Feature_name', right_on='Year', how='left')\n",
    "    merged_df['Close '] = merged_df['Close '].fillna(overall_mean_vix)\n",
    "    merged_df.drop(columns=['Year'], inplace=True)\n",
    "\n",
    "    merged_df = merged_df.sort_values(by=['Folder_name', 'Feature_name'])\n",
    "    merged_df.dropna(inplace=True)\n",
    "    merged_df.to_csv(f'output\\embeddings\\{file_name}_with_fr.csv')\n",
    "\n",
    "prepare_final_dataset(r'output\\embeddings\\ConvE_10.csv', 'ConvE_10')\n",
    "prepare_final_dataset(r'output\\embeddings\\ConvE_30.csv', 'ConvE_30')\n",
    "prepare_final_dataset(r'output\\embeddings\\TransE_10.csv', 'TransE_10')\n",
    "prepare_final_dataset(r'output\\embeddings\\TransE_30.csv', 'TransE_30')\n",
    "prepare_final_dataset(r'output\\embeddings\\TransH_10.csv', 'TransH_10')\n",
    "prepare_final_dataset(r'output\\embeddings\\TransH_30.csv', 'TransH_30')\n",
    "prepare_final_dataset(r'output\\embeddings\\RGCN_10.csv', 'RGCN_10')\n",
    "prepare_final_dataset(r'output\\embeddings\\RGCN_30.csv', 'RGCN_30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvE model with 10 embeddings\n",
      "Logistic Regression Performance:\n",
      "Test Accuracy: 0.9474\n",
      "Precision: 1.0000\n",
      "Recall: 0.8889\n",
      "F1 Score: 0.9412\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "LogisticRegression model saved!\n",
      "\n",
      "Random Forest Performance:\n",
      "Test Accuracy: 0.9474\n",
      "Precision: 1.0000\n",
      "Recall: 0.8889\n",
      "F1 Score: 0.9412\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "RandomForest model saved!\n",
      "\n",
      "XGBoost Performance:\n",
      "Test Accuracy: 0.8947\n",
      "Precision: 1.0000\n",
      "Recall: 0.7778\n",
      "F1 Score: 0.8750\n",
      "ROC AUC: 0.8889\n",
      "\n",
      "XGBoost model saved!\n",
      "\n",
      "ConvE model with 30 embeddings\n",
      "Logistic Regression Performance:\n",
      "Test Accuracy: 0.9474\n",
      "Precision: 1.0000\n",
      "Recall: 0.8571\n",
      "F1 Score: 0.9231\n",
      "ROC AUC: 0.9881\n",
      "\n",
      "LogisticRegression model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vijay\\Desktop\\B.Tech\\5th Sem\\Bankruptcy_Prediction\\.langchain\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:07:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\vijay\\Desktop\\B.Tech\\5th Sem\\Bankruptcy_Prediction\\.langchain\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance:\n",
      "Test Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "RandomForest model saved!\n",
      "\n",
      "XGBoost Performance:\n",
      "Test Accuracy: 0.8421\n",
      "Precision: 0.7000\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.8235\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "XGBoost model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vijay\\Desktop\\B.Tech\\5th Sem\\Bankruptcy_Prediction\\.langchain\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:07:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"ConvE model with 10 embeddings\")\n",
    "merge_and_train(r'output\\embeddings\\ConvE_10.csv', 'ConvE_10')\n",
    "print(\"ConvE model with 30 embeddings\")\n",
    "merge_and_train(r'output\\embeddings\\ConvE_30.csv', 'ConvE_30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransE model with 10 embeddings\n",
      "Logistic Regression Performance:\n",
      "Test Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "LogisticRegression model saved!\n",
      "\n",
      "Random Forest Performance:\n",
      "Test Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "RandomForest model saved!\n",
      "\n",
      "XGBoost Performance:\n",
      "Test Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vijay\\Desktop\\B.Tech\\5th Sem\\Bankruptcy_Prediction\\.langchain\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:06:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "XGBoost model saved!\n",
      "\n",
      "TransE model with 30 embeddings\n",
      "Logistic Regression Performance:\n",
      "Test Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "LogisticRegression model saved!\n",
      "\n",
      "Random Forest Performance:\n",
      "Test Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "RandomForest model saved!\n",
      "\n",
      "XGBoost Performance:\n",
      "Test Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "XGBoost model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vijay\\Desktop\\B.Tech\\5th Sem\\Bankruptcy_Prediction\\.langchain\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:06:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"TransE model with 10 embeddings\")\n",
    "merge_and_train(r'output\\embeddings\\TransE_10.csv', 'TransE_10')\n",
    "print(\"TransE model with 30 embeddings\")\n",
    "merge_and_train(r'output\\embeddings\\TransE_30.csv', 'TransE_30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransH model with 10 embeddings\n",
      "Logistic Regression Performance:\n",
      "Test Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "LogisticRegression model saved!\n",
      "\n",
      "Random Forest Performance:\n",
      "Test Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "RandomForest model saved!\n",
      "\n",
      "XGBoost Performance:\n",
      "Test Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "XGBoost model saved!\n",
      "\n",
      "TransH model with 30 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vijay\\Desktop\\B.Tech\\5th Sem\\Bankruptcy_Prediction\\.langchain\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:06:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\vijay\\Desktop\\B.Tech\\5th Sem\\Bankruptcy_Prediction\\.langchain\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:06:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "Test Accuracy: 0.9474\n",
      "Precision: 1.0000\n",
      "Recall: 0.8889\n",
      "F1 Score: 0.9412\n",
      "ROC AUC: 0.8889\n",
      "\n",
      "LogisticRegression model saved!\n",
      "\n",
      "Random Forest Performance:\n",
      "Test Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "RandomForest model saved!\n",
      "\n",
      "XGBoost Performance:\n",
      "Test Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "XGBoost model saved!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TransH model with 10 embeddings\")\n",
    "merge_and_train(r'output\\embeddings\\TransH_10.csv', 'TransH_10')\n",
    "print(\"TransH model with 30 embeddings\")\n",
    "merge_and_train(r'output\\embeddings\\TransH_30.csv', 'TransH_30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGCN model with 10 embeddings\n",
      "Logistic Regression Performance:\n",
      "Test Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "LogisticRegression model saved!\n",
      "\n",
      "Random Forest Performance:\n",
      "Test Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "RandomForest model saved!\n",
      "\n",
      "XGBoost Performance:\n",
      "Test Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vijay\\Desktop\\B.Tech\\5th Sem\\Bankruptcy_Prediction\\.langchain\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:06:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\vijay\\Desktop\\B.Tech\\5th Sem\\Bankruptcy_Prediction\\.langchain\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:06:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost model saved!\n",
      "\n",
      "RGCN model with 30 embeddings\n",
      "Logistic Regression Performance:\n",
      "Test Accuracy: 0.8947\n",
      "Precision: 1.0000\n",
      "Recall: 0.8462\n",
      "F1 Score: 0.9167\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "LogisticRegression model saved!\n",
      "\n",
      "Random Forest Performance:\n",
      "Test Accuracy: 0.9474\n",
      "Precision: 1.0000\n",
      "Recall: 0.9231\n",
      "F1 Score: 0.9600\n",
      "ROC AUC: 0.9359\n",
      "\n",
      "RandomForest model saved!\n",
      "\n",
      "XGBoost Performance:\n",
      "Test Accuracy: 0.9474\n",
      "Precision: 1.0000\n",
      "Recall: 0.9231\n",
      "F1 Score: 0.9600\n",
      "ROC AUC: 0.9615\n",
      "\n",
      "XGBoost model saved!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RGCN model with 10 embeddings\")\n",
    "merge_and_train(r'output\\embeddings\\RGCN_10.csv', 'RGCN_10')\n",
    "print(\"RGCN model with 30 embeddings\")\n",
    "merge_and_train(r'output\\embeddings\\RGCN_30.csv', 'RGCN_30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_values = financial_df.isnull().sum()\n",
    "# for i, j in zip(financial_df.columns, missing_values):\n",
    "#     if j > 0: print(i, j)\n",
    "\n",
    "# _embeddings_10_ce = pd.read_csv(r'output\\embeddings\\ConvE_10.csv')\n",
    "# merged_df_10_ce = pd.concat([financial_df, _embeddings_10_ce], axis=1)\n",
    "\n",
    "# _embeddings_30_ce = pd.read_csv(r'output\\embeddings\\ConvE_30.csv')\n",
    "# merged_df_30_ce = pd.concat([financial_df, _embeddings_30_ce], axis=1)\n",
    "\n",
    "# merged_df_10_ce = merged_df_10_ce.merge(vix_data, left_on='Feature_name', right_on='Year', how='left')\n",
    "# merged_df_10_ce['Close '] = merged_df_10_ce['Close '].fillna(overall_mean_vix)\n",
    "# merged_df_10_ce.drop(columns=['Year'], inplace=True)\n",
    "\n",
    "# merged_df_30_ce = merged_df_30_ce.merge(vix_data, left_on='Feature_name', right_on='Year', how='left')\n",
    "# merged_df_30_ce['Close '] = merged_df_30_ce['Close '].fillna(overall_mean_vix)\n",
    "# merged_df_30_ce.drop(columns=['Year'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_columns = ['Bankruptcy', 'path', 'Folder_name', 'Feature_name', 'Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df_10_ce = merged_df_10_ce.sort_values(by=['Folder_name', 'Feature_name'])\n",
    "# merged_df_10_ce.dropna(inplace=True)\n",
    "# X_10_ce = merged_df_10_ce.drop(columns=drop_columns)\n",
    "# y_10_ce = merged_df_10_ce[\"Label\"]\n",
    "\n",
    "# X_train_10_ce, X_test_10_ce, y_train_10_ce, y_test_10_ce = train_test_split(X_10_ce, y_10_ce, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_metrics(model_name, y_test, y_preds, y_probs):\n",
    "#     print(f\"{model_name} Performance:\")\n",
    "#     print(f\"Test Accuracy: {accuracy_score(y_test, y_preds):.4f}\")\n",
    "#     print(f\"Precision: {precision_score(y_test, y_preds):.4f}\")\n",
    "#     print(f\"Recall: {recall_score(y_test, y_preds):.4f}\")\n",
    "#     print(f\"F1 Score: {f1_score(y_test, y_preds):.4f}\")\n",
    "#     print(f\"ROC AUC: {roc_auc_score(y_test, y_probs):.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 5: Logistic Regression\n",
    "# log_model = LogisticRegression()\n",
    "# log_model.fit(X_train_10_ce, y_train_10_ce)\n",
    "# log_preds = log_model.predict(X_test_10_ce)\n",
    "# log_probs = log_model.predict_proba(X_test_10_ce)[:, 1]\n",
    "# print_metrics(\"Logistic Regression\", y_test_10_ce, log_preds, log_probs)\n",
    "# print()\n",
    "# # Step 6: Random Forest\n",
    "# rf_model = RandomForestClassifier(random_state=42)\n",
    "# rf_model.fit(X_train_10_ce, y_train_10_ce)\n",
    "# rf_preds = rf_model.predict(X_test_10_ce)\n",
    "# rf_probs = rf_model.predict_proba(X_test_10_ce)[:, 1]\n",
    "# print_metrics(\"Random Forest\", y_test_10_ce, rf_preds, rf_probs)\n",
    "# print()\n",
    "# # Step 7: XGBoost\n",
    "# xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "# xgb_model.fit(X_train_10_ce, y_train_10_ce)\n",
    "# xgb_preds = xgb_model.predict(X_test_10_ce)\n",
    "# xgb_probs = xgb_model.predict_proba(X_test_10_ce)[:, 1]\n",
    "# print_metrics(\"XGBoost\", y_test_10_ce, xgb_preds, xgb_probs)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for 30 embeddings ce\n",
    "# merged_df_30_ce = merged_df_30_ce.sort_values(by=['Folder_name', 'Feature_name'])\n",
    "# merged_df_30_ce.dropna(inplace=True)\n",
    "# X_30_ce = merged_df_30_ce.drop(columns=drop_columns)\n",
    "# y_30_ce = merged_df_30_ce[\"Label\"]\n",
    "\n",
    "# X_train_30_ce, X_test_30_ce, y_train_30_ce, y_test_30_ce = train_test_split(X_30_ce, y_30_ce, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 5: Logistic Regression\n",
    "# log_model = LogisticRegression()\n",
    "# log_model.fit(X_train_30_ce, y_train_30_ce)\n",
    "# log_preds = log_model.predict(X_test_30_ce)\n",
    "# log_probs = log_model.predict_proba(X_test_30_ce)[:, 1]\n",
    "# print_metrics(\"Logistic Regression\", y_test_30_ce, log_preds, log_probs)\n",
    "# print()\n",
    "# # Step 6: Random Forest\n",
    "# rf_model = RandomForestClassifier(random_state=42)\n",
    "# rf_model.fit(X_train_30_ce, y_train_30_ce)\n",
    "# rf_preds = rf_model.predict(X_test_30_ce)\n",
    "# rf_probs = rf_model.predict_proba(X_test_30_ce)[:, 1]\n",
    "# print_metrics(\"Random Forest\", y_test_30_ce, rf_preds, rf_probs)\n",
    "# print()\n",
    "# # Step 7: XGBoost\n",
    "# xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "# xgb_model.fit(X_train_30_ce, y_train_30_ce)\n",
    "# xgb_preds = xgb_model.predict(X_test_30_ce)\n",
    "# xgb_probs = xgb_model.predict_proba(X_test_30_ce)[:, 1]\n",
    "# print_metrics(\"XGBoost\", y_test_30_ce, xgb_preds, xgb_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
