{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <strong>Data Preprocessing and Cleaning</strong>\n",
    "\n",
    "This notebook is used to preprocess the text files from the Dataset and create the finalized Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Here is a sample of <strong>uncleaned-noisy</strong> data from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample uncleaned dataset\n",
    "\n",
    "```text\n",
    "BOARD OF DIRECTORS\n",
    "Shri Ghanshyam Das Agarwal\n",
    "-\n",
    "Non-executive Chairman\n",
    "Shri Jugal Kishore Agarwal\n",
    "-\n",
    "Non-executive Director\n",
    "Shri Nirmal Kumar Agarwal\n",
    "-\n",
    "Non-executive Director\n",
    "Shri Mohan Lal Agarwal\n",
    "\n",
    "MANAGEMENT DISCUSSION & ANALYSIS\n",
    "ADHUNIK METALIKS - AN OVERVIEW\n",
    "Your Company operates in a specialised segment of steel industry,\n",
    "producing, special alloy steel, ferro alloys, iron billets and rolled\n",
    "products at it manufacturing facility at Odisha. Though integrated\n",
    "with iron ore and manganese ore mines and a 1.6 MMTPA pellet\n",
    "making facility set up under its wholly owned subsidiary, Orissa\n",
    "Manganese & Minerals Limited, the fortune of your industry are\n",
    "dependent upon the growth and fall of iron & steel segment of\n",
    "the economy. During the year under review, the iron & steel\n",
    "industry has been plagued with several challenges relating to\n",
    "negative growth, issues with the mining sector and uncontrolled\n",
    "imports from countries with surplus capacities. Though a preferred\n",
    "supplier to many major industrial houses, your Company's\n",
    "performance has been marred due to the sharp decline in the\n",
    "performance of important customers of the Company.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is found nearly in all over the dataset so it is neccessary to remove the noise / clean our data to feed it to next phase of our methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "There are several files which dosen't contain any MD&A data (because of inaccuracy in scrapping data from financial reports) we need to remove those files from the dataset as they are of no use in our further model building and training. So we consider valid files from these set of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if management discussion and analysis section is present in the following reports\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "bankrupt_companies = os.listdir('Dataset/Final Dataset/Bankrupt')\n",
    "healthy_companies = os.listdir('Dataset/Final Dataset/Healthy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>1. Select Acceptable Data</strong>\n",
    "\n",
    "Select only files which has MD&A section in it, else do not consider it for further phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptable_bankrupt = []\n",
    "acceptable_healthy = []\n",
    "\n",
    "# only consider files which has an MD&A section else donot consider that file\n",
    "if os.access('Dataset/Final Dataset/Bankrupt', os.R_OK):\n",
    "    for company in bankrupt_companies:\n",
    "        with open('Dataset/Final Dataset/Bankrupt/' + company, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            if re.search('management discussion and analysis', text, re.IGNORECASE):\n",
    "                acceptable_bankrupt.append(company)\n",
    "\n",
    "if os.access('Dataset/Final Dataset/Healthy', os.R_OK):\n",
    "    for company in healthy_companies:\n",
    "        with open('Dataset/Final Dataset/Healthy/' + company, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            if re.search('management discussion and analysis', text, re.IGNORECASE):\n",
    "                acceptable_healthy.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptable bankrupt companies: 131 out of 201 companies.\n",
      "Acceptable healthy companies: 130 out of 298 companies.\n"
     ]
    }
   ],
   "source": [
    "print(f'Acceptable bankrupt companies: {len(acceptable_bankrupt)} out of {len(bankrupt_companies)} companies.')\n",
    "print(f'Acceptable healthy companies: {len(acceptable_healthy)} out of {len(healthy_companies)} companies.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Only 131 Bankrupt companies files and 130 Healthy companies files are good to move to the next phase of methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>2. Preprocessing Data</strong>\n",
    "\n",
    "Preprocess the data by applying lemmatization, removing punctuation, removing stopwords, lowecaseing and using other technique which are generaly used to preprocess any textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Download NLTK stopwords\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mda(mda_text):\n",
    "    \"\"\"\n",
    "    1. Lowercasing\n",
    "    2. Tokenizing\n",
    "    3. Removing punctuation\n",
    "    4. Removing stopwords\n",
    "    5. Lemmatization\n",
    "    6. NER\n",
    "    \"\"\"\n",
    "    # Convert text to lowercase\n",
    "    mda_text = mda_text.lower()\n",
    "    \n",
    "    # Sentence tokenization with NLTK\n",
    "    sentences = sent_tokenize(mda_text)\n",
    "    \n",
    "    # Process each sentence\n",
    "    processed_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # Tokenize each sentence into words\n",
    "        words = word_tokenize(sentence)\n",
    "        \n",
    "        # Remove punctuation (except for full stops) and stopwords\n",
    "        filtered_words = [word for word in words if (word.isalnum() or word == '.') and word not in stop_words]\n",
    "        \n",
    "        # Join words back into a sentence\n",
    "        processed_sentence = ' '.join(filtered_words)\n",
    "        processed_sentences.append(processed_sentence)\n",
    "    \n",
    "    # Join processed sentences back into a single text\n",
    "    cleaned_text = ' '.join(processed_sentences)\n",
    "    \n",
    "    # Lemmatization with spaCy\n",
    "    doc = nlp(cleaned_text)\n",
    "    lemmatized_tokens = [token.lemma_ if token.lemma_ != '-PRON-' else token.text for token in doc]\n",
    "    \n",
    "    # Named Entity Recognition (NER) with spaCy\n",
    "    named_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    \n",
    "    # Join lemmatized tokens back to form a preprocessed text string\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "    \n",
    "    return lemmatized_text, named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def preprocess_mda(mda_text):\n",
    "#     mda_text = mda_text.lower()         # lowercasing\n",
    "#     sentences = sent_tokenize(mda_text) # sentence tokenization\n",
    "#     processed_sentences = []                    \n",
    "#     for sentence in sentences:  \n",
    "#         words = word_tokenize(sentence) # removing punctuation and stopwords\n",
    "#         filtered_words = [word for word \n",
    "#                     in words if (word.isalnum() or word == '.')\n",
    "#                     and word not in stop_words]\n",
    "#         processed_sentence = ' '.join(filtered_words)\n",
    "#         processed_sentences.append(processed_sentence)\n",
    "#     cleaned_text = ' '.join(processed_sentences)\n",
    "    \n",
    "#     # Lemmatization with spaCy\n",
    "#     doc = nlp(cleaned_text)\n",
    "#     lemmatized_tokens = [\n",
    "#         token.lemma_ if token.lemma_ != '-PRON-' \n",
    "#         else token.text for token in doc\n",
    "#         ]\n",
    "#     lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "    \n",
    "#     return lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>3. Extract MD&A from each file</strong>\n",
    "\n",
    "Every file doesn't contain information about MD&A section, if contains it has some other useless data with it, So applied regular expression to parse out the MD&A section out of large text document we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the md&a section from the text\n",
    "def extract_mda_section(text):\n",
    "    # Define the start and end patterns for the MD&A section\n",
    "    start_pattern = r\"(?:MANAGEMENT DISCUSSION & ANALYSIS|management discussion and analysis|MD&A|MDA|Management Discussion and Analysis|management discussion)\"\n",
    "    end_pattern = r\"(?:DIRECTORS' REPORT|BOARD OF DIRECTORS|CORPORATE GOVERNANCE|CEO CERTIFICATION)\"\n",
    "\n",
    "    # Find the start and end indices\n",
    "    start_match = re.search(start_pattern, text, re.IGNORECASE)\n",
    "    end_match = re.search(end_pattern, text[start_match.end():], re.IGNORECASE) if start_match else None\n",
    "    \n",
    "    # If both start and end are found, extract the section\n",
    "    if start_match and end_match:\n",
    "        mda_section = text[start_match.start():start_match.end() + end_match.start()]\n",
    "        return mda_section.strip()\n",
    "    elif start_match:\n",
    "        # If only the start is found, extract from start to the end of the document\n",
    "        mda_section = text[start_match.start():].strip()\n",
    "        return mda_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADHUNIK_2017_MDA.txt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acceptable_bankrupt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now start extracting the text from the acceptable companies\n",
    "with open('Dataset/Final Dataset/Bankrupt/' + acceptable_bankrupt[0], 'r', encoding='latin-1') as f:\n",
    "    text = f.read()\n",
    "    mda_section = extract_mda_section(text)\n",
    "    text_data, ne = preprocess_mda(mda_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'management discussion analysis report adhunik metaliks limit 10 annual report india expect big turnaround economy also one fast grow economy however india set challenge tepid infrastructure manufacturing sector . assume average annual price crude petroleum product current account expect decrease . though may take see full policy change india decline improve current account balance provide picture previous year . growth growth expect move upward . infrastructure development increase revival manufacturing sector expect provide necessary trigger steel demand . steel demand expect grow 6 7 . however much sharper expect increase higher budget key downside risk outlook highlight world steel . risk opportunity threat steel sector intrinsically link economic growth . high economic growth india last 10 year lead increase demand steel move indian steel industry new stage growth development . increase result india become 4th large producer crude steel large producer sponge world . per capita steel also improve 48 kg 2009 61 kg however world develop economy average 217 395 caput thus present large opportunity indian steel sector . project increase demand sector like infrastructure automobile railway expect contribute demand . current depressed global environment indian steel industry face many headwind . globally steel industry oversupply . sharp currency steel country compound problem . major risk face indian steel industry uncorrelated steel price indigenous raw material price . thermal coal iron ore price high india compare global price . dynamic global indian steel change long term sustainability would dependent raw material price sustainable debt level company . context challenge face industry adhunik put place several building block enhance cost product mix high value clear focus quality improvement expand dealer network deep market order capitalise well challenge . strategy include globally cost sustained excellence . discussion financial performance respect operational performance financial discuss derive audit standalone financial statement . total revenue rs . lacs fiscal 2017 12 month compare rs . lac fiscal 2016 9 month . reason mute performance outcome several external industry factor iron steel industry large . company operate manufacturing unit instal capacity however capacity ramp could achieve due poor market . company make control cost reduce employee cost company incur tax loss rs . crore . raw material price iron ore iron ore price trend level well . price crash level due overcapacity excess supply major mining company . due subdue major consumer like china . contrast oversupply global market india witness supply crisis . closure 26 mine odisha defunct mining karnataka goa quantum supply indian market dearth iron eventually lead increase price high import india . increase royalty rate iron ore 10 15 sale price ad valorem basis act catalyst increase cost steel pellet maker . coke coal coke global coking coal price recede due low china due slow economy . also slow chinese economy result low demand coke manifest low coke price . go forward yet see whether current level coke coal coke price sustainable long run . also impact company lead closure coke oven set manufacturing odisha . capital cost management discussion analysis report contd . adhunik metaliks limit 11 annual report expend remain drag company term review . raw material management company period review procure major raw material iron ore manganese ore mine locate within radius 200 km manufacturing facility . strategy help maintain work capital cycle also minimise delay supply . coal procure overseas source establish procurement standard contract . propose merger omml would reduce cost due taxis . environment water wastewater management system number take realm wastewater recycling reuse company achieve aim zero discharge . power plant dri blast furnace steel rolling mill blow closed loop water circuit makeup industrial cool circuit . excess blow water generate use along storm water drainage plant drainage route pond suspend solid get series chamber clear water use ore washing dust suppression system development green belt . remain water pond route back raw water reservoir reuse . air pollution control measure dri hot gas waste heat recovery boiler generate power . provision bag house precipitator power plant maintain emission level . late technology use control dusty fume sms include primary secondary technology sulphur dioxide emission control process . sprinkler regularly use control minimise emission . kilns mbf furnace also line high temperature resistant refractory control heat loss protect personnel thermal . corporate social responsibility measure green'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ADHUNIK_2017_MDA.txt', 'ADVENZYM_2021_MDA.txt')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acceptable_bankrupt[0], acceptable_healthy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset/Final_Processed_Dataset/Bankrupt is not empty. Please empty the directory before running this script.\n",
      "Dataset/Final_Processed_Dataset/Healthy is not empty. Please empty the directory before running this script.\n"
     ]
    }
   ],
   "source": [
    "# os.makedirs('Dataset/Final_Dataset_Cleaned/Bankrupt', exist_ok=True)\n",
    "# os.makedirs('Dataset/Final_Dataset_Cleaned/Healthy', exist_ok=True)\n",
    "\n",
    "def preprocess_mda_and_save(acceptable_comapnies, output_dir, bankrupt=True):\n",
    "    if(os.listdir(output_dir)):\n",
    "        print(f'{output_dir} is not empty. Please empty the directory before running this script.')\n",
    "        return\n",
    "    if bankrupt:\n",
    "        for company in acceptable_comapnies:\n",
    "            if(os.path.exists('Dataset/Final Dataset/Bankrupt/' + company)):\n",
    "                with open('Dataset/Final Dataset/Bankrupt/' + company, 'r', encoding='utf-8') as f:\n",
    "                    text = f.read()\n",
    "                    mda_section = extract_mda_section(text)\n",
    "                    text_data, ne = preprocess_mda(mda_section)\n",
    "                    with open(f'{output_dir}/{company}', 'w', encoding='utf-8') as f:\n",
    "                        f.write(text_data)\n",
    "    else:\n",
    "        for company in acceptable_comapnies:\n",
    "            if(os.path.exists('Dataset/Final Dataset/Healthy/' + company)):\n",
    "                with open('Dataset/Final Dataset/Healthy/' + company, 'r', encoding='utf-8') as f:\n",
    "                    text = f.read()\n",
    "                    mda_section = extract_mda_section(text)\n",
    "                    text_data, ne = preprocess_mda(mda_section)\n",
    "                    with open(f'{output_dir}/{company}', 'w', encoding='utf-8') as f:\n",
    "                        f.write(text_data)\n",
    "            else:\n",
    "                print(f'{company} does not exist in the Healthy dataset.')\n",
    "\n",
    "\n",
    "os.makedirs('Dataset/Final_Processed_Dataset/Bankrupt', exist_ok=True)\n",
    "os.makedirs('Dataset/Final_Processed_Dataset/Healthy', exist_ok=True)\n",
    "\n",
    "preprocess_mda_and_save(acceptable_bankrupt, 'Dataset/Final_Processed_Dataset/Bankrupt')\n",
    "preprocess_mda_and_save(acceptable_healthy, 'Dataset/Final_Processed_Dataset/Healthy', bankrupt=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
