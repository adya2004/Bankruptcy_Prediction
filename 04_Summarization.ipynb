{"cells":[{"cell_type":"markdown","metadata":{},"source":["# <strong> Problem Statement: Bankruptcy Prediction using Natural Language Processing </strong>"]},{"cell_type":"markdown","metadata":{},"source":["# Summary Generation using BART(Facebook)"]},{"cell_type":"markdown","metadata":{},"source":["This notebook contain code to generate summary for each text file present in the dataset. We experimented with different models like T5, BART, etc and analysed the rouge score to select the best possible model for summerization."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:23:10.011497Z","iopub.status.busy":"2024-10-20T08:23:10.011105Z","iopub.status.idle":"2024-10-20T08:23:55.759321Z","shell.execute_reply":"2024-10-20T08:23:55.757806Z","shell.execute_reply.started":"2024-10-20T08:23:10.011460Z"},"trusted":true},"outputs":[],"source":["from transformers import pipeline, AutoTokenizer\n","import os\n","\n","# Initialize the summarization pipeline\n","summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n","\n","# Load the tokenizer to handle input tokenization\n","tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:23:09.971021Z","iopub.status.busy":"2024-10-20T08:23:09.970423Z","iopub.status.idle":"2024-10-20T08:23:10.008549Z","shell.execute_reply":"2024-10-20T08:23:10.007269Z","shell.execute_reply.started":"2024-10-20T08:23:09.970963Z"},"trusted":true},"outputs":[],"source":["def split_text(text, max_tokens=1024):\n","    # Split the document into sentences and group them into chunks that fit within max_tokens\n","    sentences = text.split('. ')\n","    chunks = []\n","    current_chunk = \"\"\n","    \n","    for sentence in sentences:\n","        if len(tokenizer.encode(current_chunk + sentence)) < max_tokens:\n","            current_chunk += sentence + '. '\n","        else:\n","            chunks.append(current_chunk)\n","            current_chunk = sentence + '. '\n","    \n","    if current_chunk:\n","        chunks.append(current_chunk)\n","    \n","    return chunks"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:23:55.761416Z","iopub.status.busy":"2024-10-20T08:23:55.760721Z","iopub.status.idle":"2024-10-20T08:23:55.774282Z","shell.execute_reply":"2024-10-20T08:23:55.772997Z","shell.execute_reply.started":"2024-10-20T08:23:55.761371Z"},"trusted":true},"outputs":[],"source":["def generate_summary(input_folder, output_folder):\n","    \n","    # Ensure the output directory exists\n","    if not os.path.exists(output_folder):\n","        os.makedirs(output_folder)\n","    \n","    n = len(os.listdir(input_folder))\n","    \n","    # Iterate over all files in the input folder\n","    counter = 0\n","    for filename in os.listdir(input_folder):\n","        # Ensure only text files are processed\n","        if filename.endswith(\".txt\"):\n","            # Construct the full file path\n","            file_path = os.path.join(input_folder, filename)\n","        \n","            # Open and read the financial document\n","            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","                financial_text = file.read()\n","        \n","            # Display the original text length\n","            print(f\"Processing file: {filename} (Original text length: {len(financial_text)})\")\n","        \n","            # Split the financial text into smaller chunks\n","            chunks = split_text(financial_text)\n","        \n","            # Summarize each chunk and combine the summaries\n","            summaries = []\n","            for chunk in chunks:\n","                # Ensure that the chunk is not too small for the model to handle\n","                if len(chunk) > 1024:\n","                    chunk = chunk[:1024]\n","        \n","                if len(chunk) > 10:  # Check if the chunk has enough content\n","                    try:\n","                        summary = summarizer(chunk, max_length=400, min_length=30, do_sample=False)\n","                        summaries.append(summary[0]['summary_text'])\n","                    except Exception as e:\n","                        print(f\"Error summarizing chunk: {e}\")\n","                        continue\n","        \n","            # Combine the summaries into one final summary\n","            final_summary = \" \".join(summaries)\n","        \n","            # Save the summary to a new file in the output folder\n","            output_file_path = os.path.join(output_folder, f\"summary_{filename}\")\n","            with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n","                output_file.write(final_summary)\n","        \n","            print(f\"Summary saved to: {output_file_path}\")\n","            counter += 1\n","            print(f\"{counter}/{n} done!\")\n","    print(\"summary generated sucessfully\")\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:23:55.778222Z","iopub.status.busy":"2024-10-20T08:23:55.777609Z","iopub.status.idle":"2024-10-20T08:24:51.737604Z","shell.execute_reply":"2024-10-20T08:24:51.736446Z","shell.execute_reply.started":"2024-10-20T08:23:55.778168Z"},"trusted":true},"outputs":[],"source":["input_folder = \"/kaggle/input/nlp-preprocessed-dataset/Final_Processed_Dataset/Bankrupt\" \n","output_folder = \"/kaggle/working/Bankruptcy\"\n","\n","generate_summary(input_folder, output_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:24:51.739758Z","iopub.status.busy":"2024-10-20T08:24:51.739371Z","iopub.status.idle":"2024-10-20T08:25:34.515770Z","shell.execute_reply":"2024-10-20T08:25:34.514558Z","shell.execute_reply.started":"2024-10-20T08:24:51.739720Z"},"trusted":true},"outputs":[],"source":["input_folder = \"/kaggle/input/nlp-preprocessed-dataset/Final_Processed_Dataset/Healthy\" \n","output_folder = \"/kaggle/working/Healthy\"\n","\n","generate_summary(input_folder, output_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:25:50.784960Z","iopub.status.busy":"2024-10-20T08:25:50.784423Z","iopub.status.idle":"2024-10-20T08:25:50.798428Z","shell.execute_reply":"2024-10-20T08:25:50.796992Z","shell.execute_reply.started":"2024-10-20T08:25:50.784892Z"},"trusted":true},"outputs":[],"source":["file = open(\"/kaggle/input/nlp-preprocessed-dataset/Final_Processed_Dataset/Bankrupt/UVSL_2016_MDA.txt\", \"r\")\n","original = file.read()\n","\n","print(original)"]},{"cell_type":"markdown","metadata":{},"source":["## Rouge score to evaluate summary"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:25:50.802529Z","iopub.status.busy":"2024-10-20T08:25:50.800712Z","iopub.status.idle":"2024-10-20T08:25:52.799364Z","shell.execute_reply":"2024-10-20T08:25:52.791354Z","shell.execute_reply.started":"2024-10-20T08:25:50.802466Z"},"trusted":true},"outputs":[],"source":["# Import the rouge_scorer module from the rouge_score package\n","from rouge_score import rouge_scorer\n","\n","# Reference text (ground truth) and summary placeholders\n","# 'reference' is the actual text from the Management Discussion and Analysis (MDA) section.\n","reference = \"\"\"\n","The Management Discussion and Analysis (MDA) section discusses the consolidated financial statements of a company as audited in accordance with Section 129 of the Companies Act 2013 and Accounting Standard 21. It highlights the salient features of the financial statements, ensuring compliance with the first proviso of Section 129 and Rule 5 of the Companies (Accounts) Rules, 2014, specifically referring to the prescribed form AOC-1 in Annexure V. Additionally, the report addresses the dividend policy in the context of accumulated losses.\n","\"\"\"\n","\n","# Open the summary file in read mode, which contains the machine-generated summary.\n","# Note: This line attempts to open the summary file, but the summary is hardcoded below as a placeholder.\n","file = open(\"/kaggle/working/Bankruptcy/summary_UVSL_2016_MDA.txt\", \"r\")\n","\n","# The 'summary' is a machine-generated text summarizing the reference content.\n","# In this case, it's a placeholder string.\n","summary = \"consolidated financial statement audit consolidated financial statement pursuant section 129 company act 2013 accounting standard 21 consolidated financial statement provide annual report. financial statement associate accordance rst proviso 3 section 129 read rule 5 company account rule 2014 prescribe form aoc 1 annex annexure v report.\"\n","\n","# Function to evaluate the machine-generated summary against the reference using ROUGE scores\n","def evaluate_summary(reference, summary):\n","    # Initialize the ROUGE scorer with the types of ROUGE metrics: ROUGE-1, ROUGE-2, and ROUGE-L.\n","    # 'use_stemmer=True' ensures word stemming (e.g., \"running\" -> \"run\") for more lenient matching.\n","    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n","    \n","    # Compute ROUGE scores between the reference and the machine-generated summary\n","    scores = scorer.score(reference, summary)\n","    \n","    # Return the computed scores\n","    return scores\n","\n","# Evaluate the summary by calling the evaluate_summary function with reference and summary as arguments\n","scores = evaluate_summary(reference, summary)\n","\n","# Print the computed ROUGE scores (Precision, Recall, and F1 Score) for each metric (ROUGE-1, ROUGE-2, ROUGE-L)\n","print(\"ROUGE Scores:\")\n","for metric, score in scores.items():\n","    print(f\"{metric}:\")\n","    print(f\"  Precision: {score.precision:.4f}\")  # Precision: The ratio of overlapping words to the total words in the summary\n","    print(f\"  Recall: {score.recall:.4f}\")        # Recall: The ratio of overlapping words to the total words in the reference\n","    print(f\"  F1 Score: {score.fmeasure:.4f}\")    # F1 Score: The harmonic mean of Precision and Recall\n"]},{"cell_type":"markdown","metadata":{},"source":["## BLEU score to evaluate summary"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-10-20T08:25:52.800555Z","iopub.status.idle":"2024-10-20T08:25:52.801055Z","shell.execute_reply":"2024-10-20T08:25:52.800840Z","shell.execute_reply.started":"2024-10-20T08:25:52.800817Z"},"trusted":true},"outputs":[],"source":["import nltk\n","from nltk.translate.bleu_score import sentence_bleu\n","\n","# Ensure you have the necessary NLTK resources\n","nltk.download('punkt')\n","\n","# Original text and summary placeholders\n","\n","\n","# Tokenize the original text and summary\n","original_tokens = nltk.word_tokenize(original)\n","summary_tokens = nltk.word_tokenize(summary)\n","\n","# Function to evaluate the BLEU score\n","def evaluate_bleu(original, summary):\n","    # Create a list of reference translations (in this case, just one)\n","    references = [original_tokens]\n","    # Calculate BLEU score\n","    bleu_score = sentence_bleu(references, summary_tokens)\n","    return bleu_score\n","\n","# Evaluate the BLEU score\n","bleu_score = evaluate_bleu(original, summary)\n","\n","# Print the BLEU score\n","print(f\"BLEU Score: {bleu_score:.4f}\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5834628,"sourceId":9572034,"sourceType":"datasetVersion"},{"datasetId":5847721,"sourceId":9588478,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
